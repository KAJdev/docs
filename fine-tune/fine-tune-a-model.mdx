---
title: "Fine Tune a model"
description: "This guide explains how to fine-tune a large language model using RunPod and Axolotl. You'll learn how to select a base model, configure your training environment, and start the fine-tuning process."
---

## Prerequisites[​](#prerequisites "Direct link to Prerequisites")

Before you begin fine-tuning, ensure you have:

* A RunPod account with access to the Fine Tuning feature
* (Optional) A Hugging Face access token for gated models

## Select a base model[​](#select-a-base-model "Direct link to Select a base model")

To start fine-tuning, you'll need to choose a base model from Hugging Face:

1. Navigate to the **Fine Tuning** section in the sidebar

2. Enter the Hugging Face model ID in the **Base Model** field

   * Example: `NousResearch/Meta-Llama-3-8B`

3. For gated models (requiring special access):

   1. Generate a Hugging Face token with appropriate permissions
   2. Add your token in the designated field

## Select a dataset[​](#select-a-dataset "Direct link to Select a dataset")

You can choose a dataset from Hugging Face for fine-tuning:

1. Browse available datasets on [Hugging Face](https://huggingface.co/datasets?task_categories=task_categories:text-generation\&sort=trending)
2. Enter your chosen dataset identifier in the **Dataset** field
   * Example: `tatsu-lab/alpaca`

## Deploy the fine-tuning pod[​](#deploy-the-fine-tuning-pod "Direct link to Deploy the fine-tuning pod")

Follow these steps to set up your training environment:

1. Click **Deploy the Fine Tuning Pod**

2. Select a GPU instance based on your model's requirements:

   * Smaller models: Choose GPUs with less memory
   * Larger models/datasets: Choose GPUs with higher memory capacity

3. Monitor the system logs for deployment progress

4. Wait for the success message: `"You've successfully configured your training environment!"`

## Connect to your training environment[​](#connect-to-your-training-environment "Direct link to Connect to your training environment")

After your pod is deployed and active, you can connect using any of these methods:

1. Go to your Fine Tuning pod dashboard

2. Click **Connect** and choose your preferred connection method:

   * **Jupyter Notebook**: Browser-based notebook interface
   * **Web Terminal**: Browser-based terminal
   * **SSH**: Local machine terminal connection

<Note>
  To use SSH, add your public SSH key in your account settings. The system automatically adds your key to the pod's `authorized_keys` file.
</Note>

## Configure your environment[​](#configure-your-environment "Direct link to Configure your environment")

Your training environment includes this directory structure in `/workspace/fine-tuning/`:

* `examples/`: Sample configurations and scripts
* `outputs/`: Training results and model outputs
* `config.yaml`: Training parameters for your model

The system generates an initial `config.yaml` based on your selected base model and dataset.

## Review and modify the configuration[​](#review-and-modify-the-configuration "Direct link to Review and modify the configuration")

The `config.yaml` file controls your fine-tuning parameters. Here's how to customize it:

1. Open the configuration file:

   ```
   nano config.yaml
   ```

2. Review and adjust the parameters based on your specific use case

Here's an example configuration with common parameters:

```
base_model: NousResearch/Meta-Llama-3.1-8B# Model loading settingsload_in_8bit: falseload_in_4bit: falsestrict: false# Dataset configurationdatasets:  - path: tatsu-lab/alpaca    type: alpacadataset_prepared_path: last_run_preparedval_set_size: 0.05output_dir: ./outputs/out# Training parameterssequence_len: 8192sample_packing: truepad_to_sequence_len: true# Weights & Biases logging (optional)wandb_project:wandb_entity:wandb_watch:wandb_name:wandb_log_model:# Training optimizationgradient_accumulation_steps: 8micro_batch_size: 1num_epochs: 1optimizer: paged_adamw_8bitlr_scheduler: cosinelearning_rate: 2e-5# Additional settingstrain_on_inputs: falsegroup_by_length: falsebf16: autofp16:tf32: falsegradient_checkpointing: truegradient_checkpointing_kwargs:  use_reentrant: falseearly_stopping_patience:resume_from_checkpoint:logging_steps: 1xformers_attention:flash_attention: truewarmup_steps: 100evals_per_epoch: 2eval_table_size:saves_per_epoch: 1debug:deepspeed:weight_decay: 0.0fsdp:fsdp_config:special_tokens:  pad_token: <|end_of_text|>
```

<Note>
  The `config.yaml` file contains all hyperparameters needed for fine-tuning. You may need to iterate on these settings to achieve optimal results.
</Note>

For more configuration examples, visit the [Axolotl examples repository](https://github.com/axolotl-ai-cloud/axolotl/tree/main/examples).

## Start the fine-tuning process[​](#start-the-fine-tuning-process "Direct link to Start the fine-tuning process")

Once your configuration is ready, follow these steps:

1. Start the training process:

   ```
   axolotl train config.yaml
   ```

2. Monitor the training progress in your terminal

## Push your model to Hugging Face[​](#push-your-model-to-hugging-face "Direct link to Push your model to Hugging Face")

After completing the fine-tuning process, you can share your model:

1. Log in to Hugging Face:

   ```
   huggingface-cli login
   ```

2. Create a new repository on Hugging Face if needed

3. Upload your model:

   ```
   huggingface-cli upload <your-username>/<model-name> ./output
   ```

Replace `<your-username>` with your Hugging Face username and `<model-name>` with your desired model name.

## Additional resources[​](#additional-resources "Direct link to Additional resources")

For more information about fine-tuning with Axolotl, see:

* [Axolotl Documentation](https://github.com/OpenAccess-AI-Collective/axolotl)

[Edit this page](https://github.com/runpod/docs/blob/main/docs/fine-tune/index.md)
